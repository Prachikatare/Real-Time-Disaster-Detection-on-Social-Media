# -*- coding: utf-8 -*-
"""Disaster_project_2(updated).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tZhPJQMBYXv8UHbCJv4_35GTt10SfaUJ
"""

# Install required libraries (run in Colab)
!pip uninstall numpy -y
!pip install transformers==4.38.2 xgboost==2.0.3 torch==2.2.1 nltk==3.8.1 scikit-learn numpy==1.26.4 --force-reinstall

import numpy as np
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score
import torch
from transformers import BertTokenizer, BertModel
import xgboost as xgb
import warnings
warnings.filterwarnings("ignore")

# Verify NumPy is working
print("NumPy version:", np.__version__)

# Download NLTK corpora
nltk.download('wordnet')
nltk.download('stopwords')

# Initialize lemmatizer
wordnet_lemmatizer = WordNetLemmatizer()

# Load dataset
train = pd.read_csv('/content/train.csv')

# Clean text function
def clean_text(text):
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"
                               u"\U0001F300-\U0001F5FF"
                               u"\U0001F680-\U0001F6FF"
                               u"\U0001F1E0-\U0001F1FF"
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               "]+", flags=re.UNICODE)
    text = emoji_pattern.sub(r'', text)
    url = re.compile(r'https?://\S+|www\.\S+')
    text = url.sub(r'', text)
    text = text.replace('#', ' ').replace('@', ' ')
    symbols = re.compile(r'[^A-Za-z0-9 ]')
    text = symbols.sub(r'', text)
    return text

# Clean and lemmatize keyword function
def clean_and_lemmatize_keyword(keyword):
    if keyword == 'None':
        return keyword
    keyword = keyword.replace('%20', ' ')
    words = keyword.split()
    lemmatized = [wordnet_lemmatizer.lemmatize(word.lower()) for word in words]
    return ' '.join(lemmatized)

# Preprocess data
train['text'] = train['text'].apply(clean_text)
train['keyword'] = train['keyword'].fillna('None').apply(clean_and_lemmatize_keyword)
train['location'] = train['location'].fillna('None')

# Combine text and keyword
X = train['text'] + ' ' + train['keyword']
y = train['target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Load BERT tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
bert_model = BertModel.from_pretrained('bert-base-uncased')

# Check for GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
bert_model.to(device)
print("Using device:", device)

# Function to get BERT embeddings
def get_bert_embeddings(texts, batch_size=32):
    bert_model.eval()
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size].tolist()
        inputs = tokenizer(batch_texts, return_tensors='pt', max_length=128, truncation=True, padding=True)
        inputs = {key: val.to(device) for key, val in inputs.items()}
        with torch.no_grad():
            outputs = bert_model(**inputs)
        # Use .detach() before converting to NumPy
        cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()
        embeddings.append(cls_embeddings)
    return np.vstack(embeddings)

# Generate embeddings for train and test sets
print("Generating BERT embeddings for training data...")
X_train_embeddings = get_bert_embeddings(X_train)
print("Generating BERT embeddings for test data...")
X_test_embeddings = get_bert_embeddings(X_test)

# Function to get BERT embeddings (updated to handle both Series and lists)
def get_bert_embeddings(texts, batch_size=32):
    bert_model.eval()
    embeddings = []
    # Check if texts is a pandas Series or a list
    if isinstance(texts, pd.Series):
        texts = texts.tolist()
    # If it's already a list, use it directly
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        inputs = tokenizer(batch_texts, return_tensors='pt', max_length=128, truncation=True, padding=True)
        inputs = {key: val.to(device) for key, val in inputs.items()}
        with torch.no_grad():
            outputs = bert_model(**inputs)
        cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()
        embeddings.append(cls_embeddings)
    return np.vstack(embeddings)

# Generate embeddings for train and test sets
print("Generating BERT embeddings for training data...")
X_train_embeddings = get_bert_embeddings(X_train)
print("Generating BERT embeddings for test data...")
X_test_embeddings = get_bert_embeddings(X_test)

# Train XGBoost
xgb_model = xgb.XGBClassifier(
    objective='binary:logistic',
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42
)

xgb_model.fit(X_train_embeddings, y_train)

# Predict and evaluate
y_pred = xgb_model.predict(X_test_embeddings)
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='binary')

print(f"\nBERT + XGBoost:")
print(f"Accuracy on test data: {accuracy:.4f}")
print(f"F1 Score on test data: {f1:.4f}")

# Function to predict disaster based on input text and keyword
def predict_disaster(text_input, keyword_input="None"):
    # Clean the input text and keyword
    cleaned_text = clean_text(text_input)
    cleaned_keyword = clean_and_lemmatize_keyword(keyword_input)

    # Combine features
    combined_input = [cleaned_text + ' ' + cleaned_keyword]  # List for compatibility with get_bert_embeddings

    # Generate BERT embeddings for the input
    input_embeddings = get_bert_embeddings(combined_input, batch_size=1)

    # Predict
    prediction = xgb_model.predict(input_embeddings)[0]

    # Return appropriate message based on prediction
    if prediction == 1:
        return "Your request is accepted. Help will arrive soon!"
    else:
        return "This does not appear to be an emergency situation."

# Example usage with interactive input
def user_interface():
    print("Enter details to check if it's a disaster situation:")
    text = input("Enter the text (e.g., tweet or message): ")
    keyword = input("Enter a keyword (optional, press Enter for none): ") or "None"

    result = predict_disaster(text, keyword)
    print("\nResult:", result)

# Run the interface
if __name__ == "__main__":
    user_interface()

""" ‘Horrible Accident  Man Died In Wings of Airplane’,  
 ‘Great day at the beach’ with no keyword—it correctly says,
"""

